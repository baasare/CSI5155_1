{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_d = pd.read_csv('data/drug_consumption.csv', header=None,\n",
    "                        names=['ID', 'Age', 'Gender', 'Education', 'Country', 'Ethnicity', 'Neuroticism',\n",
    "                               'Extraversion',\n",
    "                               'Openness-to-experience', 'Agreeableness', 'Conscientiousness', 'Impulsive',\n",
    "                               'Sensation-seeking', 'Alcohol', 'Amphet', 'Amyl', 'Benzos', 'Caff', 'Cannabis', 'Choc',\n",
    "                               'Coke', 'Crack', 'Ecstasy', 'Heroin', 'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms',\n",
    "                               'Nicotine', 'Semer', 'VSA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drugs = ['Alcohol', 'Amphet', 'Amyl', 'Benzos', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin',\n",
    "         'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms', 'Nicotine', 'Semer', 'VSA']\n",
    "\n",
    "dataset_d_binary = dataset_d.replace(['CL0', 'CL1'], \"Non-User\")\n",
    "dataset_d_binary = dataset_d_binary.replace(['CL2', 'CL3', 'CL3', 'CL4', 'CL5', 'CL6', ], \"User\")\n",
    "dataset_d_binary_drugs = dataset_d_binary[drugs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drugs_value_count = dataset_d_binary_drugs.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trace1 = go.Bar(\n",
    "    x=drugs,\n",
    "    y=drugs_value_count.iloc[1],\n",
    "    name='User',\n",
    "    marker=dict(color=\"rgb(117, 127, 221)\")\n",
    ")\n",
    "trace2 = go.Bar(\n",
    "    x=drugs,\n",
    "    y=drugs_value_count.iloc[0],\n",
    "    name='Non-User',\n",
    "    marker=dict(color=\"rgb(191, 221, 229)\")\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    title='Drug Vs User Or Non-user',\n",
    "    yaxis=dict(title='Count', ticklen=5, gridwidth=2),\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pk = drugs_value_count.iloc[1]\n",
    "col = [i for i in range(len(pk.values))]\n",
    "data = [\n",
    "    go.Bar(\n",
    "        x=list(pk.index),\n",
    "        y=list(pk.values),\n",
    "        marker=dict(color=col, colorscale='Jet', showscale=False)\n",
    "    ), ]\n",
    "layout = go.Layout(\n",
    "    title='Used Drugs Vs Number of Users',\n",
    "    yaxis=dict(title='Users', ticklen=5, gridwidth=2),\n",
    "    xaxis=dict(title='Drugs', ticklen=5, gridwidth=2),\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='Drug-Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "from scipy.stats import friedmanchisquare\n",
    "from scikit_posthocs import posthoc_nemenyi_friedman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models_1 = {\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest Classifier': RandomForestClassifier(n_estimators=100),\n",
    "    'Support Vector Machines': SVC(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "}\n",
    "\n",
    "models_2 = {\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest Classifier': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Support Vector Machines': SVC(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Multi Layer Perceptron': MLPClassifier(hidden_layer_sizes=(256, 128, 64, 32), solver=\"adam\",\n",
    "                                            learning_rate='adaptive', activation=\"relu\", random_state=42),\n",
    "    'Gradient Boosting Ensemble': GradientBoostingClassifier(n_estimators=50),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "benzos_dataset_d = pd.concat([dataset_d_binary.iloc[:, 0:13], dataset_d_binary[drugs]['Benzos']], axis=1, join='inner')\n",
    "benzos_dataset_d['Benzos'] = le.fit_transform(benzos_dataset_d['Benzos'])\n",
    "benzos_dataset_d = benzos_dataset_d.drop('ID', axis=1)\n",
    "\n",
    "coke_dataset_d = pd.concat([dataset_d_binary.iloc[:, 0:13], dataset_d_binary[drugs]['Coke']], axis=1, join='inner')\n",
    "coke_dataset_d['Coke'] = le.fit_transform(coke_dataset_d['Coke'])\n",
    "coke_dataset_d = coke_dataset_d.drop('ID', axis=1)\n",
    "\n",
    "estacy_dataset_d = pd.concat([dataset_d_binary.iloc[:, 0:13], dataset_d_binary[drugs]['Ecstasy']], axis=1, join='inner')\n",
    "estacy_dataset_d['Coke'] = le.fit_transform(estacy_dataset_d['Ecstasy'])\n",
    "estacy_dataset_d = estacy_dataset_d.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scoring = 'accuracy'\n",
    "scoring_1 = 'f1'\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "X = benzos_dataset_d.drop('Benzos', axis=1)\n",
    "y = benzos_dataset_d['Benzos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_models(models, _X, _y, _cv, _scoring):\n",
    "    model_performance = []\n",
    "    for name, model in models.items():\n",
    "        model.fit(X, y)\n",
    "        _scores = cross_val_score(estimator=model, X=_X, y=_y, scoring=_scoring, cv=_cv)\n",
    "        model_performance.append(_scores.mean())\n",
    "        print(name)\n",
    "        print('Mean Accuracy: {:.2%}'.format(_scores.mean()))\n",
    "        print()\n",
    "    return model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_models(models_1, X, y, cv, scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "over = RandomOverSampler(random_state=42)\n",
    "over_smote = SMOTE()\n",
    "X_db1, y_db1 = over_smote.fit_resample(X, y)\n",
    "\n",
    "print('Random Over Sampling')\n",
    "\n",
    "train_models(models_1, X_db1, y_db1, cv, scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "under = RandomUnderSampler(random_state=42)\n",
    "X_db2, y_db2 = under.fit_resample(X, y)\n",
    "\n",
    "print('Random Under Sampling')\n",
    "\n",
    "train_models(models_1, X_db2, y_db2, cv, scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('NORMAL')\n",
    "performance_d = train_models(models_2, X, y, cv, scoring)\n",
    "\n",
    "print('RANDOM OVER SAMPLING')\n",
    "performance_d1 = train_models(models_2, X_db1, y_db1, cv, scoring)\n",
    "\n",
    "print('RANDOM UNDER SAMPLING')\n",
    "performance_d2 = train_models(models_2, X_db2, y_db2, cv, scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_h = pd.read_csv('data/heart_cleveland_upload.csv')\n",
    "\n",
    "X_h = dataset_h.drop('condition', axis=1)\n",
    "y_h = dataset_h['condition']\n",
    "\n",
    "print('Heart Disease')\n",
    "\n",
    "performance_h = train_models(models_2, X_h, y_h, cv, scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_l = pd.read_csv('data/labor.csv', na_values=[\"?\"])\n",
    "dataset_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_l.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_l.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=dataset_l['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "features = ['cost-of-living-adjustment', 'pension', 'education-allowance', 'vacation', 'longterm-disability-assistance',\n",
    "            'contribution-to-dental-plan', 'bereavement-assistance', 'contribution-to-health-plan', 'class']\n",
    "for feature in features:\n",
    "    dataset_l[feature] = le.fit_transform(dataset_l[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "X_l = knn_imputer.fit_transform(dataset_l.drop('class', axis=1))\n",
    "y_l = dataset_l['class']\n",
    "\n",
    "print('LABOUR')\n",
    "\n",
    "performance_l = train_models(models_2, X_l, y_l, cv, scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "performance = [performance_d, performance_d1, performance_d2, performance_h, performance_l]\n",
    "performance_df = pd.DataFrame(performance, columns=['Decision Tree', 'Random Forest Classifier', 'Support Vector Machines', 'KNN', 'Multi Layer Perceptron', 'Gradient Boosting Ensemble'])\n",
    "\n",
    "performance_df.insert(0, \"Dataset\", ['D', 'DB1', 'DB2', 'heart-disease', 'labor-relations'])\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compare models\n",
    "stat, p = friedmanchisquare(\n",
    "    performance_df['Decision Tree'],\n",
    "    performance_df['Random Forest Classifier'],\n",
    "    performance_df['Support Vector Machines'],\n",
    "    performance_df['KNN'],\n",
    "    performance_df['Multi Layer Perceptron'],\n",
    "    performance_df['Gradient Boosting Ensemble']\n",
    ")\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')\n",
    "    print(posthoc_nemenyi_friedman(performance_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}